---
title: "p8105_hw3_kzw2102"
author: "Kelly Wang"
date: "10/13/19"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
devtools::install_github("thomasp85/patchwork")
library(patchwork)
library(tidyverse)
library(viridis)
library(ggridges)
library(lubridate)
library(dplyr)
```

# Problem 1
* how many aisles are there? Which aisles are the most important. 
* plot that shows number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly and organize plot so can read it * table that shows most popular items in each of the aisles "baking ingredients", "dog food care" and "packaged vegetables fruits".  (including number of times each item is ordered in your table)

```{r}
library(p8105.datasets)
data("instacart")
instacart %>% 
  janitor::clean_names()
``` 
```{r}
# counting how many aisles there are 
instacart %>% 
  summarize(
     max(aisle_id)
  )
```
```{r count_aisles}
#counting the aisles that are the most important : there are 134 aisles 
instacart %>% 
  count(aisle_id, name = "n_items")
# another  way
instacart %>% 
  group_by(aisle_id) %>% 
  summarize(
    n_obs=n()
  )
## to get the max
instacart %>% 
  add_count(aisle_id, name = "n_items") %>% 
  summarize(
    max(aisle_id, n_items)
)
# most frequent aisle has 150609 items in it -- aisle_id = 83. 
```
## plot that shows number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. 
```{r insta_plot}
instacart_plot = 
  instacart %>%
  group_by(aisle_id) %>% 
  summarize(
    n_obs=n()
  ) %>% 
  filter(n_obs > 10000)%>% 
  ggplot(aes(x=aisle_id, y=n_obs)) + 
  geom_point(aes(color=n_obs), alpha=0.3) + 
  labs(
    title = "Items ordered in each aisle plot",
    x = "Aisle ID",
    y= "number of items ordered"
  ) 

instacart_plot
```

## table that shows the three most popular in each of the aisles "baking ingredients", "dog food care", "packaged vegetables fruits"

??????
```{r table}
top_three_df=
instacart %>% 
  group_by(aisle, product_name) %>% 
  filter(
    aisle==c("baking ingredients","dog food care", "packaged vegetables fruits")
  ) %>% 
  group_by(aisle) %>% 
  top_n(3, n_obs)


```
## table for mean hour of day at which Pink Lady Apples and Coffe Ice Cream were ordered
?? sometimes prints sometimes doesnt
```{r pinklady table}
mean_hour_df=
instacart %>% 
  filter(product_name == c("Pink Lady Apples", "Coffe Ice Cream")) %>% 
  select(product_name, order_dow, order_hour_of_day) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(
    mean_order_hour=mean(order_hour_of_day)
  ) %>%  
  mutate(
    order_dow = recode(order_dow, '1' = "Monday", '2'= "Tuesday", '3' = "Wednesday", '4'= "Thursday", '5'="Friday", '6'="Saturday", '0'="Sunday")
  ) %>% 
  pivot_wider(
    names_from=order_dow,
    values_from=mean_order_hour
  )  %>% 
knitr::kable(digits=2)

```

In this dataset, there are `r nrow(instacart)` rows and `r ncol(instacart)` variables/columns.There are a total of 134 aisles, where aisle 83, also known as "Fresh vegetables" contains the most amount of items, which is (150,609 items). Majority of the aisles have under 4000 products, based off of the plot. 

# Question 2
```{r}
library(p8105.datasets)
data("brfss_smart2010")
```
### cleaning the data
```{r}
brfss_df=
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  rename(location_abbr=locationabbr, location_desc=locationdesc, resp_id=respid) %>%
  filter(topic=="Overall Health") %>% 
  filter(response==c("Excellent", "Very Good","Good", "Fair", "Poor")) %>% 
  response = factor(c("Excellent", "Very Good","Good", "Fair", "Poor"), levels=c("Excellent", "Very Good","Good", "Fair", "Poor"))
???
```

### in 2002, which states observed 7 or more locations?
```{r}
brfss_df %>% 
  filter(year==2002) %>% 
  group_by(location_abbr) %>% 
  summarize(
    n_locations=n()
  ) %>% 
  filter(n_locations >= 7) %>% 
  knitr::kable()
```

### in 2010, which states were observed at 7 or more locations?
```{r}
brfss_df %>% 
  filter(year==2010) %>% 
  group_by(location_abbr) %>% 
  summarize(
    n_locations=n()
  ) %>% 
  filter(n_locations >= 7) %>% 
  knitr::kable()
```
### Excellent table
```{r}
brfss_excellent_df=
  brfss_df %>% 
  filter(response=="Excellent") %>% 
  select(year, location_abbr, location_desc, data_value) %>% 
  group_by(location_desc, year) %>% 
  summarize(
    average_data_value= mean(data_value)
  )

## spaghetti plot
brfss_excellent_plot=
  brfss_excellent_df %>% 
  ggplot(aes(x=year, y=average_data_value, color=location_abbr))+ geom_line()+
  labs(
    title="Average data_value per State",
    x = "Year",
    y = "Average data value",
    color = 'State'
  )

brfss_excellent_plot

## not workign again. :(
```

### two panel plot that shows the distribution of of data_value responses among locations in NY State
```{r}
##panels you use patchwork
plot2006= 
brfss_df %>% 
  filter(year=="2006", location_abbr== "NY") %>% 
  ggplot(aes(x=location_desc, y=data_value, color=response))+
           geom_point(alpha=0.5)
  
plot2010 =
  brfss_df %>% 
  filter(year=="2010", location_abbr== "NY") %>% 
  ggplot(aes(x=location_desc, y=data_value, color=response))+
           geom_point(alpha=0.5)
plot2006 / plot2010
```
# Problem 3
```{r}
accel_data=
  read_csv(file="./accel_data.csv")

# tidy the data
accel_tidy_data=
  accel_data %>% 
  janitor::clean_names()
  
```


